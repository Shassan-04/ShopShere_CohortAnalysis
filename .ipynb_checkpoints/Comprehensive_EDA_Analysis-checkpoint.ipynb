{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "comprehensive-eda-title",
   "metadata": {},
   "source": [
    "# Comprehensive Exploratory Data Analysis for ShopSphere E-Commerce\n",
    "## Focus: Customer Retention & Cohort Analysis Insights\n",
    "\n",
    "This analysis provides actionable insights for solving customer retention challenges through data-driven approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better visualizations\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-loading",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare data\n",
    "df = pd.read_csv(\"ShopSphere_Dataset.csv\")\n",
    "\n",
    "# Data preprocessing\n",
    "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
    "df['CustomerID'] = df['CustomerID'].astype('object')\n",
    "df['Revenue'] = df['Quantity'] * df['UnitPrice']\n",
    "\n",
    "# Extract date components for time-based analysis\n",
    "df['Year'] = df['InvoiceDate'].dt.year\n",
    "df['Month'] = df['InvoiceDate'].dt.month\n",
    "df['Quarter'] = df['InvoiceDate'].dt.quarter\n",
    "df['DayOfWeek'] = df['InvoiceDate'].dt.day_name()\n",
    "df['Hour'] = df['InvoiceDate'].dt.hour\n",
    "\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(f\"Date Range: {df['InvoiceDate'].min()} to {df['InvoiceDate'].max()}\")\n",
    "print(f\"Total Revenue: ${df['Revenue'].sum():,.2f}\")\n",
    "print(f\"Unique Customers: {df['CustomerID'].nunique():,}\")\n",
    "print(f\"Unique Products: {df['StockCode'].nunique():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-1",
   "metadata": {},
   "source": [
    "## 1. Customer Behavior Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "customer-metrics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer-level metrics for retention analysis\n",
    "customer_metrics = df.groupby('CustomerID').agg({\n",
    "    'InvoiceNo': 'nunique',  # Number of orders\n",
    "    'Revenue': ['sum', 'mean'],  # Total and average revenue\n",
    "    'Quantity': 'sum',  # Total items purchased\n",
    "    'InvoiceDate': ['min', 'max'],  # First and last purchase dates\n",
    "    'Description': 'nunique'  # Product variety\n",
    "}).round(2)\n",
    "\n",
    "# Flatten column names\n",
    "customer_metrics.columns = ['Orders', 'Total_Revenue', 'Avg_Revenue', 'Total_Items', \n",
    "                           'First_Purchase', 'Last_Purchase', 'Product_Variety']\n",
    "\n",
    "# Calculate customer lifetime (days between first and last purchase)\n",
    "customer_metrics['Customer_Lifetime_Days'] = (\n",
    "    customer_metrics['Last_Purchase'] - customer_metrics['First_Purchase']\n",
    ").dt.days\n",
    "\n",
    "# Calculate days since last purchase (recency)\n",
    "analysis_date = df['InvoiceDate'].max()\n",
    "customer_metrics['Days_Since_Last_Purchase'] = (\n",
    "    analysis_date - customer_metrics['Last_Purchase']\n",
    ").dt.days\n",
    "\n",
    "print(\"Customer Metrics Summary:\")\n",
    "print(customer_metrics.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "customer-segmentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer Segmentation based on behavior\n",
    "def categorize_customer(row):\n",
    "    if row['Orders'] >= 10 and row['Total_Revenue'] >= 5000:\n",
    "        return 'VIP'\n",
    "    elif row['Orders'] >= 5 and row['Total_Revenue'] >= 2000:\n",
    "        return 'Loyal'\n",
    "    elif row['Orders'] >= 3:\n",
    "        return 'Regular'\n",
    "    else:\n",
    "        return 'New/Occasional'\n",
    "\n",
    "customer_metrics['Customer_Segment'] = customer_metrics.apply(categorize_customer, axis=1)\n",
    "\n",
    "# Segment distribution\n",
    "segment_dist = customer_metrics['Customer_Segment'].value_counts()\n",
    "print(\"Customer Segment Distribution:\")\n",
    "print(segment_dist)\n",
    "print(f\"\\nPercentage Distribution:\")\n",
    "print((segment_dist / segment_dist.sum() * 100).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retention-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer Retention Analysis\n",
    "def analyze_retention():\n",
    "    # Define retention periods\n",
    "    retention_periods = [30, 60, 90, 180, 365]\n",
    "    retention_rates = {}\n",
    "    \n",
    "    for period in retention_periods:\n",
    "        # Customers who made their first purchase more than 'period' days ago\n",
    "        eligible_customers = customer_metrics[\n",
    "            customer_metrics['Days_Since_Last_Purchase'] >= period\n",
    "        ]\n",
    "        \n",
    "        if len(eligible_customers) > 0:\n",
    "            # Customers who made a purchase within the period\n",
    "            retained_customers = eligible_customers[\n",
    "                eligible_customers['Customer_Lifetime_Days'] >= period\n",
    "            ]\n",
    "            \n",
    "            retention_rate = len(retained_customers) / len(eligible_customers) * 100\n",
    "            retention_rates[f'{period}_days'] = retention_rate\n",
    "    \n",
    "    return retention_rates\n",
    "\n",
    "retention_rates = analyze_retention()\n",
    "print(\"Customer Retention Rates:\")\n",
    "for period, rate in retention_rates.items():\n",
    "    print(f\"{period}: {rate:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-2",
   "metadata": {},
   "source": [
    "## 2. Product and Category Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "product-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product category performance\n",
    "category_performance = df.groupby('Description').agg({\n",
    "    'Revenue': ['sum', 'mean', 'count'],\n",
    "    'Quantity': 'sum',\n",
    "    'CustomerID': 'nunique'\n",
    "}).round(2)\n",
    "\n",
    "category_performance.columns = ['Total_Revenue', 'Avg_Revenue', 'Transactions', \n",
    "                               'Total_Quantity', 'Unique_Customers']\n",
    "\n",
    "# Calculate revenue percentage\n",
    "category_performance['Revenue_Percentage'] = (\n",
    "    category_performance['Total_Revenue'] / category_performance['Total_Revenue'].sum() * 100\n",
    ").round(2)\n",
    "\n",
    "# Sort by total revenue\n",
    "category_performance = category_performance.sort_values('Total_Revenue', ascending=False)\n",
    "\n",
    "print(\"Top Product Categories by Revenue:\")\n",
    "print(category_performance.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cross-selling-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-selling analysis - Products frequently bought together\n",
    "from itertools import combinations\n",
    "\n",
    "# Get products bought in same transaction\n",
    "transaction_products = df.groupby('InvoiceNo')['Description'].apply(list).reset_index()\n",
    "\n",
    "# Find product pairs\n",
    "product_pairs = []\n",
    "for products in transaction_products['Description']:\n",
    "    if len(products) > 1:\n",
    "        for pair in combinations(products, 2):\n",
    "            product_pairs.append(sorted(pair))\n",
    "\n",
    "# Count frequency of pairs\n",
    "pair_counts = pd.DataFrame(product_pairs, columns=['Product_A', 'Product_B'])\n",
    "pair_frequency = pair_counts.groupby(['Product_A', 'Product_B']).size().reset_index(name='Frequency')\n",
    "pair_frequency = pair_frequency.sort_values('Frequency', ascending=False)\n",
    "\n",
    "print(\"Top Product Pairs (Cross-selling Opportunities):\")\n",
    "print(pair_frequency.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-3",
   "metadata": {},
   "source": [
    "## 3. Temporal Patterns and Seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "temporal-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly trends\n",
    "monthly_trends = df.groupby(['Year', 'Month']).agg({\n",
    "    'Revenue': 'sum',\n",
    "    'InvoiceNo': 'nunique',\n",
    "    'CustomerID': 'nunique'\n",
    "}).reset_index()\n",
    "\n",
    "monthly_trends['Date'] = pd.to_datetime(monthly_trends[['Year', 'Month']].assign(day=1))\n",
    "\n",
    "print(\"Monthly Business Trends:\")\n",
    "print(monthly_trends.tail(12))\n",
    "\n",
    "# Day of week patterns\n",
    "dow_patterns = df.groupby('DayOfWeek').agg({\n",
    "    'Revenue': ['sum', 'mean'],\n",
    "    'InvoiceNo': 'nunique'\n",
    "}).round(2)\n",
    "\n",
    "dow_patterns.columns = ['Total_Revenue', 'Avg_Revenue', 'Transactions']\n",
    "\n",
    "# Reorder by weekday\n",
    "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "dow_patterns = dow_patterns.reindex(day_order)\n",
    "\n",
    "print(\"\\nDay of Week Patterns:\")\n",
    "print(dow_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hourly-patterns",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hourly shopping patterns\n",
    "hourly_patterns = df.groupby('Hour').agg({\n",
    "    'Revenue': 'sum',\n",
    "    'InvoiceNo': 'nunique',\n",
    "    'CustomerID': 'nunique'\n",
    "}).round(2)\n",
    "\n",
    "hourly_patterns.columns = ['Total_Revenue', 'Transactions', 'Unique_Customers']\n",
    "\n",
    "print(\"Peak Shopping Hours:\")\n",
    "print(hourly_patterns.sort_values('Total_Revenue', ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-4",
   "metadata": {},
   "source": [
    "## 4. Geographic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geographic-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Country-wise performance\n",
    "country_performance = df.groupby('Country').agg({\n",
    "    'Revenue': ['sum', 'mean'],\n",
    "    'CustomerID': 'nunique',\n",
    "    'InvoiceNo': 'nunique',\n",
    "    'Quantity': 'sum'\n",
    "}).round(2)\n",
    "\n",
    "country_performance.columns = ['Total_Revenue', 'Avg_Revenue', 'Unique_Customers', \n",
    "                              'Transactions', 'Total_Quantity']\n",
    "\n",
    "# Calculate metrics per customer\n",
    "country_performance['Revenue_Per_Customer'] = (\n",
    "    country_performance['Total_Revenue'] / country_performance['Unique_Customers']\n",
    ").round(2)\n",
    "\n",
    "country_performance['Transactions_Per_Customer'] = (\n",
    "    country_performance['Transactions'] / country_performance['Unique_Customers']\n",
    ").round(2)\n",
    "\n",
    "print(\"Country Performance Analysis:\")\n",
    "print(country_performance.sort_values('Total_Revenue', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-5",
   "metadata": {},
   "source": [
    "## 5. Cohort Analysis for Customer Retention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cohort-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cohort Analysis\n",
    "def create_cohort_analysis():\n",
    "    # Get customer's first purchase date\n",
    "    customer_cohort = df.groupby('CustomerID')['InvoiceDate'].min().reset_index()\n",
    "    customer_cohort.columns = ['CustomerID', 'CohortGroup']\n",
    "    customer_cohort['CohortGroup'] = customer_cohort['CohortGroup'].dt.to_period('M')\n",
    "    \n",
    "    # Merge with main dataframe\n",
    "    df_cohort = df.merge(customer_cohort, on='CustomerID')\n",
    "    df_cohort['InvoiceDate'] = df_cohort['InvoiceDate'].dt.to_period('M')\n",
    "    \n",
    "    # Calculate period number (months since first purchase)\n",
    "    df_cohort['PeriodNumber'] = (\n",
    "        df_cohort['InvoiceDate'] - df_cohort['CohortGroup']\n",
    "    ).apply(attrgetter('n'))\n",
    "    \n",
    "    # Create cohort table\n",
    "    cohort_data = df_cohort.groupby(['CohortGroup', 'PeriodNumber'])['CustomerID'].nunique().reset_index()\n",
    "    cohort_counts = cohort_data.pivot(index='CohortGroup', columns='PeriodNumber', values='CustomerID')\n",
    "    \n",
    "    # Calculate cohort sizes\n",
    "    cohort_sizes = cohort_counts.iloc[:, 0]\n",
    "    \n",
    "    # Calculate retention rates\n",
    "    retention_rates = cohort_counts.divide(cohort_sizes, axis=0)\n",
    "    \n",
    "    return cohort_counts, retention_rates\n",
    "\n",
    "from operator import attrgetter\n",
    "\n",
    "try:\n",
    "    cohort_counts, retention_rates = create_cohort_analysis()\n",
    "    print(\"Cohort Retention Rates (first 6 months):\")\n",
    "    print(retention_rates.iloc[:, :6].round(3))\n",
    "    \n",
    "    # Average retention by period\n",
    "    avg_retention = retention_rates.mean().round(3)\n",
    "    print(\"\\nAverage Retention Rates by Period:\")\n",
    "    for i, rate in enumerate(avg_retention[:12]):\n",
    "        print(f\"Month {i}: {rate:.1%}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Cohort analysis error: {e}\")\n",
    "    print(\"Proceeding with alternative retention analysis...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-6",
   "metadata": {},
   "source": [
    "## 6. RFM Analysis (Recency, Frequency, Monetary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rfm-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFM Analysis for customer segmentation\n",
    "rfm_data = df.groupby('CustomerID').agg({\n",
    "    'InvoiceDate': 'max',  # Last purchase date\n",
    "    'InvoiceNo': 'nunique',  # Frequency\n",
    "    'Revenue': 'sum'  # Monetary value\n",
    "}).reset_index()\n",
    "\n",
    "rfm_data.columns = ['CustomerID', 'LastPurchase', 'Frequency', 'Monetary']\n",
    "\n",
    "# Calculate Recency (days since last purchase)\n",
    "rfm_data['Recency'] = (analysis_date - rfm_data['LastPurchase']).dt.days\n",
    "\n",
    "# Create RFM scores (1-5 scale)\n",
    "rfm_data['R_Score'] = pd.qcut(rfm_data['Recency'].rank(method='first'), 5, labels=[5,4,3,2,1])\n",
    "rfm_data['F_Score'] = pd.qcut(rfm_data['Frequency'].rank(method='first'), 5, labels=[1,2,3,4,5])\n",
    "rfm_data['M_Score'] = pd.qcut(rfm_data['Monetary'].rank(method='first'), 5, labels=[1,2,3,4,5])\n",
    "\n",
    "# Combine RFM scores\n",
    "rfm_data['RFM_Score'] = rfm_data['R_Score'].astype(str) + rfm_data['F_Score'].astype(str) + rfm_data['M_Score'].astype(str)\n",
    "\n",
    "# Define customer segments based on RFM\n",
    "def rfm_segment(row):\n",
    "    if row['RFM_Score'] in ['555', '554', '544', '545', '454', '455', '445']:\n",
    "        return 'Champions'\n",
    "    elif row['RFM_Score'] in ['543', '444', '435', '355', '354', '345', '344', '335']:\n",
    "        return 'Loyal Customers'\n",
    "    elif row['RFM_Score'] in ['512', '511', '422', '421', '412', '411', '311']:\n",
    "        return 'Potential Loyalists'\n",
    "    elif row['RFM_Score'] in ['533', '532', '531', '523', '522', '521', '515', '514', '513', '425', '424', '413', '414', '415', '315', '314', '313']:\n",
    "        return 'New Customers'\n",
    "    elif row['RFM_Score'] in ['155', '154', '144', '214', '215', '115', '114']:\n",
    "        return 'At Risk'\n",
    "    elif row['RFM_Score'] in ['255', '254', '245', '244', '253', '252', '243', '242', '235', '234', '225', '224', '153', '152', '145', '143', '142', '135', '134', '125', '124']:\n",
    "        return 'Cannot Lose Them'\n",
    "    else:\n",
    "        return 'Others'\n",
    "\n",
    "rfm_data['Segment'] = rfm_data.apply(rfm_segment, axis=1)\n",
    "\n",
    "# RFM segment distribution\n",
    "segment_summary = rfm_data.groupby('Segment').agg({\n",
    "    'CustomerID': 'count',\n",
    "    'Recency': 'mean',\n",
    "    'Frequency': 'mean',\n",
    "    'Monetary': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "segment_summary.columns = ['Customer_Count', 'Avg_Recency', 'Avg_Frequency', 'Avg_Monetary']\n",
    "segment_summary['Percentage'] = (segment_summary['Customer_Count'] / segment_summary['Customer_Count'].sum() * 100).round(2)\n",
    "\n",
    "print(\"RFM Customer Segments:\")\n",
    "print(segment_summary.sort_values('Customer_Count', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-7",
   "metadata": {},
   "source": [
    "## 7. Key Insights and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insights-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate key insights\n",
    "print(\"=\" * 60)\n",
    "print(\"KEY INSIGHTS FOR CUSTOMER RETENTION STRATEGY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. Customer Segmentation Insights\n",
    "print(\"\\n1. CUSTOMER SEGMENTATION INSIGHTS:\")\n",
    "print(\"-\" * 40)\n",
    "segment_dist_pct = (customer_metrics['Customer_Segment'].value_counts() / len(customer_metrics) * 100).round(1)\n",
    "for segment, pct in segment_dist_pct.items():\n",
    "    print(f\"   • {segment}: {pct}% of customers\")\n",
    "\n",
    "# 2. Revenue Concentration\n",
    "print(\"\\n2. REVENUE CONCENTRATION:\")\n",
    "print(\"-\" * 40)\n",
    "top_20_pct_customers = int(len(customer_metrics) * 0.2)\n",
    "top_20_revenue = customer_metrics.nlargest(top_20_pct_customers, 'Total_Revenue')['Total_Revenue'].sum()\n",
    "total_revenue = customer_metrics['Total_Revenue'].sum()\n",
    "revenue_concentration = (top_20_revenue / total_revenue * 100)\n",
    "print(f\"   • Top 20% customers generate {revenue_concentration:.1f}% of total revenue\")\n",
    "\n",
    "# 3. Product Category Performance\n",
    "print(\"\\n3. TOP PERFORMING CATEGORIES:\")\n",
    "print(\"-\" * 40)\n",
    "top_categories = category_performance.head(3)\n",
    "for idx, (category, data) in enumerate(top_categories.iterrows(), 1):\n",
    "    print(f\"   {idx}. {category}: ${data['Total_Revenue']:,.0f} ({data['Revenue_Percentage']:.1f}% of total)\")\n",
    "\n",
    "# 4. Geographic Insights\n",
    "print(\"\\n4. GEOGRAPHIC PERFORMANCE:\")\n",
    "print(\"-\" * 40)\n",
    "for country, data in country_performance.iterrows():\n",
    "    print(f\"   • {country}: ${data['Revenue_Per_Customer']:,.0f} revenue per customer\")\n",
    "\n",
    "# 5. Temporal Patterns\n",
    "print(\"\\n5. SHOPPING PATTERNS:\")\n",
    "print(\"-\" * 40)\n",
    "peak_day = dow_patterns['Total_Revenue'].idxmax()\n",
    "peak_hour = hourly_patterns['Total_Revenue'].idxmax()\n",
    "print(f\"   • Peak shopping day: {peak_day}\")\n",
    "print(f\"   • Peak shopping hour: {peak_hour}:00\")\n",
    "\n",
    "# 6. Customer Lifetime Value\n",
    "print(\"\\n6. CUSTOMER LIFETIME VALUE:\")\n",
    "print(\"-\" * 40)\n",
    "avg_clv = customer_metrics['Total_Revenue'].mean()\n",
    "median_clv = customer_metrics['Total_Revenue'].median()\n",
    "print(f\"   • Average CLV: ${avg_clv:.2f}\")\n",
    "print(f\"   • Median CLV: ${median_clv:.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ACTIONABLE RECOMMENDATIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n🎯 RETENTION STRATEGIES:\")\n",
    "print(\"   1. Focus on 'At Risk' customers with personalized offers\")\n",
    "print(\"   2. Implement loyalty programs for 'Potential Loyalists'\")\n",
    "print(\"   3. Create VIP experiences for 'Champions' segment\")\n",
    "\n",
    "print(\"\\n📊 CROSS-SELLING OPPORTUNITIES:\")\n",
    "print(\"   1. Bundle frequently bought-together products\")\n",
    "print(\"   2. Recommend complementary categories to single-category buyers\")\n",
    "\n",
    "print(\"\\n⏰ TIMING OPTIMIZATION:\")\n",
    "print(f\"   1. Schedule marketing campaigns for {peak_day}s\")\n",
    "print(f\"   2. Optimize website performance during {peak_hour}:00 hour\")\n",
    "\n",
    "print(\"\\n🌍 GEOGRAPHIC EXPANSION:\")\n",
    "if len(country_performance) > 1:\n",
    "    best_country = country_performance['Revenue_Per_Customer'].idxmax()\n",
    "    print(f\"   1. Replicate {best_country} success strategies in other markets\")\n",
    "    print(\"   2. Investigate market-specific preferences for localization\")\n",
    "\n",
    "print(\"\\n💰 REVENUE OPTIMIZATION:\")\n",
    "print(\"   1. Increase average order value through upselling\")\n",
    "print(\"   2. Focus on high-margin categories for promotion\")\n",
    "print(\"   3. Implement dynamic pricing for peak hours/days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This comprehensive EDA reveals critical insights for improving customer retention:\n",
    "\n",
    "### Key Findings:\n",
    "1. **Customer Segmentation**: Clear distinction between customer tiers with different value contributions\n",
    "2. **Revenue Concentration**: Small percentage of customers drive majority of revenue\n",
    "3. **Behavioral Patterns**: Distinct shopping patterns by time and geography\n",
    "4. **Retention Opportunities**: Identifiable at-risk customers requiring intervention\n",
    "\n",
    "### Next Steps:\n",
    "1. Implement targeted retention campaigns based on RFM segments\n",
    "2. Develop cohort-specific marketing strategies\n",
    "3. Create predictive models for customer churn\n",
    "4. A/B test retention interventions\n",
    "\n",
    "This analysis provides the foundation for data-driven customer retention strategies that can significantly impact business growth and customer lifetime value."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}